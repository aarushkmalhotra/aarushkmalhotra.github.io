[
  {
    "id": "vernato",
    "name": "Vernato",
    "tagline": "AI powered pronunciation platform",
    "description": "Vernato helps people practice speaking and get clear feedback that they can use right away. The app listens to short clips, scores them, and shows what to fix next. It is built for learners and teachers who want a simple way to measure progress without fuss.\nThe goal is to reduce guesswork. You speak. You see your score in accuracy, fluency, and completeness. You get a small tip. Then you try again. Over time the small wins add up and your voice gets stronger.",
    "role": "I lead product and engineering. I set the scoring goals, wrote the early model eval scripts, and built the web app with a clean flow from record to feedback. I also handle cloud setup, CI, and data privacy. When needed I do design reviews and write copy so the product feels simple.",
    "problem": "Learners practice speaking but do not know what good sounds like or if they are improving. Teachers want a quick signal that is fair and repeatable. The tools that exist are either hard to use or feel like a black box with vague advice.",
    "approach": "Start with a clear scoring idea and ship a small end to end slice. Collect short clips, build a basic model, and show a simple score card. Add guardrails for noisy input. Keep the interface calm. Do weekly tests with real users and fold their notes back into the product. Use cloud services only where they save time.",
    "challenges": "Making feedback useful without long text was hard. We tried color, icons, and short lines to guide the next try. Handling room noise and phone mics took careful filtering and thresholds. Keeping latency low while scoring audio in the cloud needed caching and tight payloads.",
    "keyFeatures": [
      "PronScoreâ„¢ model for comprehensive feedback",
      "Actionable insights on accuracy, fluency, and completeness",
      "Designed for individuals, educators, and organizations",
      "Engaging and measurable pronunciation training"
    ],
    "techStack": "TypeScript, React, Next.js, Azure, Google Cloud, Firebase, Vercel, Tailwind CSS, Git",
    "keywords": ["AI & Machine Learning", "Web Development", "Creative Tech"],
    "outcomes": "We shipped a working beta that scores short speech clips and returns feedback in under two seconds for most cases. Early users report that the score card makes practice feel focused and less random.\nWe built a small data loop for testing new model tweaks against real sessions. This helps us guard against regressions and keep guidance clear as we grow the dataset.",
    "repoUrl": null,
    "demoUrl": "https://www.vernato.org",
    "images": ["vernato-1"],
    "startDate": "2025-06-01",
    "endDate": null,
    "type": "project",
     "theme": {
      "primary": "hsl(196, 75%, 52%)",
      "secondary": "hsl(45, 100%, 55%)"
    }
  },
  {
    "id": "emty",
    "name": "EMTY Commuting App",
    "tagline": "Real time subway car occupancy",
    "description": "EMTY shows riders which cars are busy so they can spread out and save time. The focus was a clean map view and a simple bar for each car that updates in real time. I worked on this in a course that mixed product thinking with hands on building.\nThe project taught me how to balance design and data. We kept the flow fast for people on the move. We wrote copy that uses plain words so anyone can trust what they see at a glance.",
    "role": "I led the product work and built the core UI in Figma. I explored real time options and mocked data flows for testing. I also prepared the pitch deck and ran demos for mentors and guests.",
    "problem": "Commuters enter a packed car while the next one is half empty. They cannot see load data in time to act. The city wants to reduce crowding and improve safety without adding new trains.",
    "approach": "Design a view that updates smoothly and never overwhelms. Use simple colors for load levels. Make the app useful even with spotty service. Keep the number of taps low so the rider gets info and moves.",
    "challenges": "Live data is messy. When feeds lag or drop, the UI must not flicker or mislead. We added small hints for stale data and smoothing for spikes. We kept assets light so it still feels quick.",
    "keyFeatures": [
      "Live visualization of subway car occupancy data",
      "Designed UX in Figma for intuitive data display",
      "Secure real-time backend with Firebase",
      "Pitched to the U.S. Capitol and Congressman's office"
    ],
    "techStack": "Figma, Canva, Firebase, MTA API",
    "keywords": ["UI/UX & Design"],
    "outcomes": "We built a working design system and a clickable prototype that tells a clear story. The demo showed how small cues can change rider flow in busy stations.\nThe work earned a Gold Award in class and opened doors to share the idea with local leaders. It also set a base for future tests with live feeds.",
    "repoUrl": null,
    "demoUrl": "https://linktr.ee/emty7",
    "images": ["emty-1"],
    "startDate": "2024-08-01",
    "endDate": "2025-04-01",
    "type": "project",
     "theme": {
      "primary": "hsl(210, 40%, 50%)",
      "secondary": "hsl(160, 60%, 45%)"
    }
  },
  {
    "id": "simplify-me",
    "name": "Simplify Me.",
    "tagline": "Terms of Service in plain English",
    "description": "Most people skip long legal pages because they are hard to read and slow to search. Simplify Me turns those pages into short notes that you can scan in seconds. You get what data is collected, how it is used, and who gets to see it.\nThe site runs on a trusted open community source and adds a simple view and clear language. It helps you make a choice without fear that you missed a key detail.",
    "role": "I built the site, wrote the prompts that guide the summaries, and set up the content flow with WordPress and Zapier. I handled the layout and the copy so the tone is friendly and honest.",
    "problem": "Privacy policies are long and full of legal terms. People need quick facts in normal words. They also want to know if a service is safe enough for them.",
    "approach": "Use a mix of community grades and light AI to draft a short view. Keep the claims tied to the source text. Show the main points first. Offer a link to the policy for people who want the full detail.",
    "challenges": "Legal text can be tricky. It is easy to over promise or miss context. We added checks and kept language neutral. We also watched for changes in policies and made sure updates flow through.",
    "keyFeatures": [
      "Translates complex legal jargon into plain English",
      "Summarizes key data collection and privacy policies",
      "Highlights how your data is used and shared",
      "Powered by the ToS;DR community-driven infrastructure"
    ],
    "techStack": "JavaScript, PHP, WordPress, Zapier, Google Gemini, CSS, HTML",
    "keywords": ["AI & Machine Learning", "Web Development", "Creative Tech"],
    "outcomes": "People can understand what they agree to in a minute instead of twenty. The site has helped many users spot red flags and make a better call for their needs.\nThe project now has a stable pipeline from source to summary. It is easy to add new services and keep things fresh without heavy manual work.",
    "repoUrl": null,
    "demoUrl": "https://simplifyme.org",
    "images": ["simplify-me-1"],
    "startDate": "2023-01-01",
    "endDate": "2025-05-01",
    "type": "project",
    "theme": {
      "primary": "hsl(267, 95%, 48%)",
      "secondary": "hsl(14, 99%, 57%)"
    }
  },
  {
    "id": "simply",
    "name": "Simply",
    "tagline": "Discord bot that explains policies",
    "description": "Simply is a Discord bot that reads long policy text and gives a clear summary. It can handle PDFs, images, and pasted text. It keeps short memory of the chat so you can ask follow up questions.\nThe bot started as a way to test the engine that now powers Simplify Me. The Discord setting made it easy to try new ideas and collect feedback from real people.",
    "role": "I wired the Discord API, set up the model calls, and tuned the prompts for short and honest answers. I deployed to a small cloud box and set up logging so I could watch errors and fix them fast.",
    "problem": "Reading big policies in chat is slow and not fun. People want a straight answer to a simple question. They also want to trust that the answer is tied to the source text.",
    "approach": "Keep the loop tight. Ingest the file, chunk the text, and answer with quotes. Use short follow ups to refine the result. Clear the chat on request so people control their data.",
    "challenges": "Large files push the limits. We had to guard against timeouts and rate limits. Image to text steps can fail in the wild, so we added retries and user tips. We also learned to keep answers to the point.",
    "keyFeatures": [
      "Multi-Format Support: Processes various file types, including images, PDFs, and text files.",
      "Contextual Analysis: Maintains a history window of up to 15 previous messages for coherent conversations.",
      "Privacy Control: Users can reset and clear their message history at any time.",
      "Performance and Scalability: Runs on Python in an Amazon EC2 instance for reliable performance.",
      "High-Accuracy Summaries: Extensively trained on legal texts to handle documents up to 70,000 words."
    ],
    "techStack": "Python, AWS, Google Gemini, Discord API",
    "keywords": ["AI & Machine Learning", "Creative Tech"],
    "outcomes": "We shipped a bot that handled real questions and documents from users. It proved the core idea and helped shape the rules that keep answers grounded.\nThe same engine now supports the summaries on Simplify Me, which means our early design choices continue to pay off.",
    "repoUrl": "https://github.com/aarushkmalhotra/Simply",
    "demoUrl": "https://simplifyme.org/Simply",
    "images": ["simply-1"],
    "startDate": "2024-01-01",
    "endDate": "2024-07-01",
    "type": "project",
    "theme": {
      "primary": "hsl(221, 83%, 53%)",
      "secondary": "hsl(210, 40%, 96.1%)"
    }
  },
  {
    "id": "youtube-thumbnails",
    "name": "YouTube Thumbnails",
    "tagline": "Design for video stories",
    "description": "I design all the thumbnails for my channel. Each one begins with a small sketch and a clear goal for what the viewer should feel. I test type, color, and light to draw the eye without tricks.\nGood design is not loud. It is clear. The goal is to earn a click with honest cues about the story inside the video.",
    "role": "I plan concepts, create assets, and do all the edits. I manage a small library of styles so the channel looks consistent. I also keep notes on which ideas perform better and why.",
    "problem": "Videos compete in a busy feed. If the cover is messy, people scroll past. I needed a repeatable way to ship good covers fast.",
    "approach": "Build a simple system. Use a few type sizes and a short color set. Keep faces clear and the idea front and center. Save templates for different formats so production is fast.",
    "challenges": "It is easy to over build. I learned to stop early and keep the message simple. Exporting for different screens can break edges and text, so I run a quick check on phone and desktop.",
    "keyFeatures": [
      "Conceptualization and sketching of thumbnail ideas.",
      "Advanced photo manipulation and compositing in Photoshop.",
      "Vector asset creation with Illustrator and GIMP.",
      "Typography and color theory to maximize click-through rate.",
      "Consistent branding across channel content."
    ],
    "techStack": "Adobe Photoshop, Adobe Illustrator, GIMP",
    "keywords": ["UI/UX & Design", "Creative Tech"],
    "outcomes": "The channel has a steady visual style and better watch starts. The covers do a better job of setting clear expectations which helps with trust over time.\nThis work also feeds back into product design. Clear type and layout choices make apps easier to use and content easier to scan.",
    "repoUrl": null,
    "demoUrl": "https://www.youtube.com/@sunbeam20/",
    "images": ["yt-thumb-2", "yt-thumb-4", "yt-thumb-1", "yt-thumb-3"],
    "startDate": "2022-09-01",
    "endDate": "2023-08-01",
    "type": "project",
    "theme": {
      "primary": "hsl(0, 100%, 50%)",
      "secondary": "hsl(0, 0%, 13%)"
    }
  },
  {
    "id": "rvc-ui",
    "name": "RVC UI & Songs",
    "tagline": "Voice conversion for music",
    "description": "I explored retrieval based voice conversion to create new song covers. The system maps a source voice to a target voice and keeps the melody. I set up the pipeline on my own machine and learned how each step shapes the final sound.\nTo push myself I also trained a small model on my own voice. It showed me how data quality and cleaning matter even more than model size.",
    "role": "I ran the full stack from data prep to model runs to final mix. I tuned slices, removed noise, and compared settings to find a clean output. I also built a simple UI so friends could try it.",
    "problem": "People want to hear a familiar voice sing a new song, but the raw tools can be hard to use. Setups break. Files clip. Outputs sound harsh.",
    "approach": "Start with careful data work. Pick clean stems, trim silence, and normalize levels. Use moderate settings to avoid artifacts, then adjust by ear. Keep notes for each run so changes are clear.",
    "challenges": "GPU memory was tight, so I had to batch small and avoid waste. Some songs needed extra de echo steps. Matching tone between verses took extra passes.",
    "keyFeatures": [
      "Utilized Retrieval-Based Voice Conversion (RVC) for voice transformation.",
      "Leveraged pre-trained models to generate AI song covers.",
      "Created a custom voice dataset to experiment with model training.",
      "Hands-on experience with local AI model implementation."
    ],
    "techStack": "PyTorch, Gradio, Python, CUDA",
    "keywords": ["AI & Machine Learning", "Creative Tech"],
    "outcomes": "I produced clean samples that keep pitch and timing while changing the voice. Tests with friends helped me find settings that sound natural.\nThe project also made me better at audio work, from noise control to gain staging, which carries over to other creative and tech work.",
    "repoUrl": null,
    "demoUrl": null,
    "images": ["rvc-1"],
    "startDate": "2023-07-01",
    "endDate": "2024-01-01",
    "type": "project",
    "theme": {
      "primary": "hsl(330, 80%, 55%)",
      "secondary": "hsl(20, 80%, 55%)"
    },
    "audioFiles": [
      {
        "id": "yetu-ne-kya-kiya",
        "title": "Ye Tune Kya Kiya - AI Cover",
        "file": "/arijit_1000_yetunekyakiya.mp3",
        "originalArtist": "Javed Bashir",
        "originalComposer": "Pritam",
        "originalLyricist": "Rajat Arora",
        "originalLabel": "T-Series"
      },
      {
        "id": "ajab-si",
        "title": "Ajab Si - AI Cover",
        "file": "/arijit_1100_ajabsi.mp3",
        "originalArtist": "KK",
        "originalComposer": "Vishal-Shekhar",
        "originalLyricist": "Vishal Dadlani",
        "originalLabel": "T-Series"
      }
    ]
  },
  {
    "id": "cifar-10-cnn",
    "name": "CIFAR-10 CNN",
    "tagline": "Image classification with a CNN",
    "description": "I worked as a scholar at Veritas AI on a group project that used the CIFAR 10 dataset. We built a CNN that can sort small images into ten classes. We learned how to design layers, pick loss functions, and watch for overfit.\nThe work was guided by a mentor who pushed us to explain each choice. This made the final model easier to trust and improves how we think about experiments.",
    "role": "I coordinated training runs, tuned learning rates, and tracked results. I wrote parts of the report and presented the final demo to our cohort.",
    "problem": "We needed a small model that performs well on low resolution images. It had to train in a short time and give clear signals that we could analyze.",
    "approach": "Start with a simple baseline and add one idea at a time such as batch norm, dropout, and data aug. Keep notes for each change and compare against the same seed so we could tell what helped.",
    "challenges": "Small images are noisy. If we made the model too big it learned the training set and missed the point. We had to use aug and regularize while watching the curve.",
    "keyFeatures": [
      "Custom Convolutional Neural Network (CNN) architecture",
      "Trained on the CIFAR-10 dataset for object recognition",
      "Led a group capstone project as a Veritas AI Scholar",
      "Mentored by a Harvard PhD candidate in Computer Science"
    ],
    "techStack": "Python, TensorFlow, CNN, Deep Learning, Google Colab",
    "keywords": ["AI & Machine Learning"],
    "outcomes": "We built a model that performs well on the test set and learned to balance capacity with generalization. The report and slides explain the trade offs in plain terms.\nMore important than a single score, the team built a habit of testing one idea at a time. That skill now shows up in later projects.",
    "repoUrl": null,
    "demoUrl": "https://docs.google.com/presentation/d/1SxtFXwkSP7j3ouTHC2i0pD7lLCfUJtWJVXgNG7_GLuo/",
    "images": [
      "cifar-1"
    ],
    "startDate": "2024-09-01",
    "endDate": "2024-11-01",
    "type": "project",
    "theme": {
      "primary": "hsl(204, 86%, 53%)",
      "secondary": "hsl(348, 100%, 61%)"
    }
  },
   {
    "id": "imdb-top-1000",
    "name": "IMDB Top 1000",
    "tagline": "My first JavaScript project",
    "description": "I built a simple app in App Lab to search and browse the top IMDB movies. It taught me how to work with arrays, events, and state. It also showed me how small UI choices change the way people explore a list.\nI added search, filters, and a basic detail view. The goal was to keep the code clear so I could extend it later.",
    "role": "I wrote the code, designed the screens, and debugged my way through plenty of small mistakes. I learned to read errors instead of guessing.",
    "problem": "I needed a project to learn the basics for the AP class and to prove to myself that I could build something end to end.",
    "approach": "Start small and ship features one at a time. Add search. Then add a detail card. Then add sorting. Keep the code neat and name things well.",
    "challenges": "I struggled with off by one bugs and state that gets out of sync. Slow loops made the UI feel stuck, so I learned to keep work simple and cache small things.",
    "keyFeatures": [
      "Browse and search IMDB's top 1000 movies",
      "Built with vanilla JavaScript on Code.org",
      "Demonstrates fundamental data manipulation and UI skills"
    ],
    "techStack": "JavaScript, Code.org App Lab",
    "keywords": ["UI/UX & Design", "Academic"],
    "outcomes": "I finished a working app that made me feel more at home with code. It gave me confidence to take on bigger projects and learn better tools.\nThe project still reminds me that clear UI and small steps beat fancy code when you are starting out.",
    "repoUrl": null,
    "demoUrl": "https://studio.code.org/projects/applab/w8PJdUtl1-DUKphmZ3zI9p0ZFzbPeqC5T_C0WHmYhVU",
    "images": ["imdb-top-1000-1"],
    "videoPreview": "/imdbtop1000demo.mp4",
    "hoverVideo": "/imdbtop1000demo.mp4",
    "startDate": "2023-09-01",
    "endDate": "2024-05-01",
    "type": "project",
    "theme": {
      "primary": "hsl(45, 93%, 54%)",
      "secondary": "hsl(0, 0%, 10%)"
    }
  },
  {
    "id": "album-tracks",
    "name": "Album Tracks",
    "tagline": "Original tracks for video",
    "description": "I wrote and produced a small set of tracks for my videos. Each track started with a simple loop and a mood. I shaped the sound with EQ and light compression and kept the mix roomy so it blends with voice.\nMusic taught me patience. Small changes in tempo or tone can change the feel of a scene. That care shows up in my code work too.",
    "role": "I composed, arranged, and mixed the songs. I exported clean versions and stems so I could reuse parts later.",
    "problem": "Stock music often misses the tone I want. I needed songs that fit the cut and support the story.",
    "approach": "Pick a tempo, pick a key, and build around a simple hook. Keep layers light so the track supports the video. Bounce drafts and listen on different speakers.",
    "challenges": "Balancing bass and kick on small speakers was tricky. Some DAW effects sounded great alone and messy in the full mix. I learned to trust my ears and remove parts.",
    "keyFeatures": [
      "Original tracks composed in SoundTrap and GarageBand",
      "Designed for use in video montages",
      "Exploration of digital audio workstation (DAW) software",
      "Focus on creating atmospheric and rhythmic beats"
    ],
    "techStack": "SoundTrap, GarageBand, Digital Audio Production",
    "keywords": ["Creative Tech"],
    "outcomes": "I built a small library of songs that match different scenes and speeds. They raised the quality of my videos and gave me more control over the final cut.\nAlong the way I learned core audio skills that help me work better with sound in other projects too.",
    "repoUrl": null,
    "demoUrl": "https://drive.google.com/drive/folders/1DrceaX2DRv2ve6mYF7210ikESgcIUKOd",
    "images": ["album-tracks-1"],
    "videoPreview": "https://youtu.be/SWiwfNcLjWg",
    "hoverVideo": "/sunbeam-the-album-full.mp4",
    "startDate": "2022-03-01",
    "endDate": "2022-09-01",
    "type": "project",
    "theme": {
      "primary": "hsl(280, 80%, 60%)",
      "secondary": "hsl(50, 90%, 55%)"
    },
    "downloadableAudioFiles": [
      {
        "id": "edm-piano-beats",
        "title": "EDM Piano Beats",
        "file": "/edm-beats-voice.wav"
      },
      {
        "id": "edm-synth-beats",
        "title": "EDM Synth Beats",
        "file": "/edm-synth-beats.mp3"
      }
    ]
  }
]
